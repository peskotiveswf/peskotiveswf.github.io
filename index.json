[{"authors":["admin"],"categories":null,"content":"I\u0026rsquo;m a 2nd year PhD student in the Spoken Language Systems Group at MIT CSAIL, working with Dr. James Glass.\nI am currently working on various projects on language and speech, including automatic fact-checking and end-to-end speech synthesis. I am generally interested in machine learning algorithms for natural language and speech, including but not limited to learning and analyzing representations, language understanding, and transfer learning for NLP and speech.\nDuring my undergrad studies at National Taiwan University (NTU), I researched on speech and language understanding under Prof. Hung-Yi Lee and Prof. Lin-Shan Lee, and worked on machine learning problems for computer vision under Prof. Yu-Chiang Frank Wang at Academia Sinica/NTU. I also interned twice with the NLP team at Apple in California.\nHere is my Curriculum Vitae (updated Sep 2019).\n","date":1572739200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1572739200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://people.csail.mit.edu/weifang/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/weifang/authors/admin/","section":"authors","summary":"I\u0026rsquo;m a 2nd year PhD student in the Spoken Language Systems Group at MIT CSAIL, working with Dr. James Glass.\nI am currently working on various projects on language and speech, including automatic fact-checking and end-to-end speech synthesis. I am generally interested in machine learning algorithms for natural language and speech, including but not limited to learning and analyzing representations, language understanding, and transfer learning for NLP and speech.\nDuring my undergrad studies at National Taiwan University (NTU), I researched on speech and language understanding under Prof.","tags":null,"title":"Wei Fang","type":"authors"},{"authors":null,"categories":null,"content":" Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://people.csail.mit.edu/weifang/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/weifang/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"https://people.csail.mit.edu/weifang/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/weifang/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":" Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"https://people.csail.mit.edu/weifang/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/weifang/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":["Wei Fang","Moin Nadeem","Mitra Mohtarami","James Glass"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/).-- ","date":1572739200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572739200,"objectID":"e3614d73649e21a9ed4679ff45fe9a4a","permalink":"https://people.csail.mit.edu/weifang/publication/emnlp19w-stance/","publishdate":"2019-09-03T00:00:00Z","relpermalink":"/weifang/publication/emnlp19w-stance/","section":"publication","summary":"We present a multi-task learning model that leverages large amount of textual information from existing datasets to improve stance prediction. In particular, we utilize multiple NLP tasks under both unsupervised and supervised settings for the target stance prediction task. Our model obtains state-of-the-art performance on a public benchmark dataset, Fake News Challenge, outperforming current approaches by a wide margin.","tags":null,"title":"Neural Multi-Task Learning for Stance Prediction","type":"publication"},{"authors":["Wei Fang","Yu-An Chung","James Glass"],"categories":null,"content":"","date":1560744000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560744000,"objectID":"449c6ed49438ca27f41a775b98c4b5ea","permalink":"https://people.csail.mit.edu/weifang/publication/arxiv19-berttaco/","publishdate":"2019-06-17T00:00:00-04:00","relpermalink":"/weifang/publication/arxiv19-berttaco/","section":"publication","summary":"Modern text-to-speech (TTS) systems are able to generate audio that sounds almost as natural as human speech. However, the bar of developing high-quality TTS systems remains high since a sizable set of studio-quality pairs is usually required. Compared to commercial data used to develop state-of-the-art systems, publicly available data are usually worse in terms of both quality and size. Audio generated by TTS systems trained on publicly available data tends to not only sound less natural, but also exhibits more background noise. In this work, we aim to lower TTS systems' reliance on high-quality data by providing them the textual knowledge extracted by deep pre-trained language models during training. In particular, we investigate the use of BERT to assist the training of Tacotron-2, a state of the art TTS consisting of an encoder and an attention-based decoder. BERT representations learned from large amounts of unlabeled text data are shown to contain very rich semantic and syntactic information about the input text, and have potential to be leveraged by a TTS system to compensate the lack of high-quality data. We incorporate BERT as a parallel branch to the Tacotron-2 encoder with its own attention head. For an input text, it is simultaneously passed into BERT and the Tacotron-2 encoder. The representations extracted by the two branches are concatenated and then fed to the decoder. As a preliminary study, although we have not found incorporating BERT into Tacotron-2 generates more natural or cleaner speech at a human-perceivable level, we observe improvements in other aspects such as the model is being significantly better at knowing when to stop decoding such that there is much less babbling at the end of the synthesized audio and faster convergence during training.","tags":[],"title":"Towards Transfer Learning for End-to-End Speech Synthesis from Deep Pre-Trained Language Models","type":"publication"},{"authors":["Chia-Hsuan Lee","Hung-Yi Lee","Szu-Lin Wu","Chi-Liang Liu","Wei Fang","Jui-Yang Hsu","Bo-Hsiang Tseng"],"categories":null,"content":"","date":1556337600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556337600,"objectID":"84c8a2f509ee7885e30d8de65254aabb","permalink":"https://people.csail.mit.edu/weifang/publication/taslp19-qa/","publishdate":"2019-04-27T00:00:00-04:00","relpermalink":"/weifang/publication/taslp19-qa/","section":"publication","summary":"Although multimedia or spoken content presents more attractive information than plain text content, the former is more difficult to display on a screen and be selected by a user. As a result, for humans, accessing large collections of spoken content is much more difficult and time-consuming than doing so for text content. It would therefore be helpful to develop machines which understand spoken content. In this paper, we propose two new tasks for machine comprehension of spoken content. The first is a listening comprehension test for TOEFL, a challenging academic English examination for English learners whose native languages are not English. We show that the proposed model outperforms the naive approaches and other neural network based models by exploiting the hierarchical structures of natural languages and the selective power of attention mechanism. For the second listening comprehension task – spoken SQuAD – we find that speech recognition errors severely impair machine comprehension; we propose the use of subword units to mitigate the impact of these errors.","tags":[],"title":"Machine Comprehension of Spoken Content: TOEFL Listening Test and Spoken SQuAD","type":"publication"},{"authors":["Moin Nadeem","Wei Fang","Brian Xu","Mitra Mohtarami","James Glass"],"categories":null,"content":"","date":1554091200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554091200,"objectID":"ac38a71332d28bfbbace7a913a5d32ed","permalink":"https://people.csail.mit.edu/weifang/publication/naacl19-faktademo/","publishdate":"2019-04-01T00:00:00-04:00","relpermalink":"/weifang/publication/naacl19-faktademo/","section":"publication","summary":"We present FAKTA which is a unified framework that integrates various components of a fact checking process: document retrieval from media sources with various types of reliability, stance detection of documents with respect to given claims, evidence extraction, and linguistic analysis. FAKTA predicts the factuality of given claims and provides evidence at the document and sentence level to explain its predictions.","tags":[],"title":"FAKTA: An Automatic End-to-End Fact Checking System","type":"publication"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://people.csail.mit.edu/weifang/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/weifang/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1548806400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548806400,"objectID":"73630c1289d3b8dcdaa54dfb73ac0400","permalink":"https://people.csail.mit.edu/weifang/project/sls19-factchecking/","publishdate":"2019-01-30T00:00:00Z","relpermalink":"/weifang/project/sls19-factchecking/","section":"project","summary":"With the rapid increase of fake news in social media and its negative influence on people and public opinion, we present FAKTA, an unified framework for automatic fact checking that predicts the factuality of given claims and provides evidence at the document and sentence level to explain its predictions.","tags":["natural-language-processing","deep-learning"],"title":"Automatic Fact Checking","type":"project"},{"authors":["Chung-Wei Lee","Wei Fang","Chih-Kuan Yeh","Yu-Chiang Frank Wang"],"categories":null,"content":"","date":1529294400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529294400,"objectID":"8d941df49a370d12eda06086249b8897","permalink":"https://people.csail.mit.edu/weifang/publication/cvpr18-mlzsl/","publishdate":"2018-06-18T00:00:00-04:00","relpermalink":"/weifang/publication/cvpr18-mlzsl/","section":"publication","summary":"In this paper, we propose a novel deep learning architecture for multi-label zero-shot learning (ML-ZSL), which is able to predict multiple unseen class labels for each input instance. Inspired by the way humans utilize semantic knowledge between objects of interests, we propose a framework that incorporates knowledge graphs for describing the relationships between multiple labels. Our model learns an information propagation mechanism from the semantic label space, which can be applied to model the interdependencies between seen and unseen class labels. With such investigation of structured knowledge graphs for visual reasoning, we show that our model can be applied for solving multi-label classification and ML-ZSL tasks. Compared to state-of-the-art approaches, comparable or improved performances can be achieved by our method.","tags":[],"title":"Multi-Label Zero-Shot Learning with Structured Knowledge Graphs","type":"publication"},{"authors":null,"categories":null,"content":"Inspired by the way humans utilize semantic knowledge between objects of interests, we propose a novel deep learning framework that incorporates knowledge graphs for describing the relationships between multiple labels to achieve multi-label zero-shot learning (ML-ZSL).\n","date":1525132800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525132800,"objectID":"d9e9f87497e5ba204561c6ffc92f904a","permalink":"https://people.csail.mit.edu/weifang/project/vll18-mlzsl/","publishdate":"2018-05-01T00:00:00Z","relpermalink":"/weifang/project/vll18-mlzsl/","section":"project","summary":"Inspired by the way humans utilize semantic knowledge between objects of interests, we propose a novel deep learning framework that incorporates knowledge graphs for describing the relationships between multiple labels to achieve multi-label zero-shot learning (ML-ZSL).","tags":["computer-vision","deep-learning"],"title":"Multi-Label ZSL with Knowledge Graphs","type":"project"},{"authors":null,"categories":null,"content":"In this project, we built a modular dialogue system with deep learning techniques for the task of assisting people in department stores.\nHere is our poster.\n","date":1498003200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498003200,"objectID":"84668b2e963b34c6ef4a9df6e4e59f96","permalink":"https://people.csail.mit.edu/weifang/project/icb17-chatbot/","publishdate":"2017-06-21T00:00:00Z","relpermalink":"/weifang/project/icb17-chatbot/","section":"project","summary":"We built a modular dialogue system with deep learning techniques for the task of assisting people in department stores.","tags":["natural-language-processing","deep-learning"],"title":"Modular Chatbot","type":"project"},{"authors":["Wei Fang","Jui-Yang Hsu","Hung-Yi Lee","Lin-Shan Lee"],"categories":null,"content":"","date":1481605200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1481605200,"objectID":"a5cee528baa037349a922156d5bb72c0","permalink":"https://people.csail.mit.edu/weifang/publication/slt16-toeflqa/","publishdate":"2016-12-13T00:00:00-05:00","relpermalink":"/weifang/publication/slt16-toeflqa/","section":"publication","summary":"Multimedia or spoken content presents more attractive information than plain text content, but the former is more difficult to display on a screen and be selected by a user. As a result, accessing large collections of the former is much more difficult and time-consuming than the latter for humans. It's therefore highly attractive to develop machines which can automatically understand spoken content and summarize the key information for humans to browse over. In this endeavor, a new task of machine comprehension of spoken content was proposed recently. The initial goal was defined as the listening comprehension test of TOEFL, a challenging academic English examination for English learners whose native languages are not English. An Attention-based Multi-hop Recurrent Neural Network (AMRNN) architecture was also proposed for this task, which considered only the sequential relationship within the speech utterances. In this paper, we propose a new Hierarchical Attention Model (HAM), which constructs multi-hopped attention mechanism over tree-structured rather than sequential representations for the utterances. Improved comprehension performance robust with respect to ASR errors were obtained.","tags":[],"title":"Hierarchical Attention Model for Improved Machine Comprehension of Spoken Content","type":"publication"},{"authors":null,"categories":null,"content":"Here is a short talk I gave on SPMLLab\u0026rsquo;s recent work on speech question answering in .\n","date":1481605200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1481605200,"objectID":"a14647a22e1effdef4d02e0b8e9112a3","permalink":"https://people.csail.mit.edu/weifang/project/spml16-toeflqa/","publishdate":"2016-12-13T00:00:00-05:00","relpermalink":"/weifang/project/spml16-toeflqa/","section":"project","summary":"Here is a short talk I gave on SPMLLab\u0026rsquo;s recent work on speech question answering in .","tags":["natural-language-processing","speech-processing","deep-learning"],"title":"QA for TOEFL Listening Comprehension","type":"project"},{"authors":null,"categories":null,"content":"In the 2016 HackNTU Hackathon, our team developed MasterView, a virtual reality system that shows the expert\u0026rsquo;s moves in first-person perspective so the user can imitate and practice.\nHere\u0026rsquo;s a demo video of our system, and here\u0026rsquo;s our presentation slides in Mandarin Chinese.\n","date":1471752000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471752000,"objectID":"f995adbceb4da628ebfd5b6983bfc53a","permalink":"https://people.csail.mit.edu/weifang/project/hackntu16-masterview/","publishdate":"2016-08-21T00:00:00-04:00","relpermalink":"/weifang/project/hackntu16-masterview/","section":"project","summary":"At the 2016 HackNTU Hackathon, our team developed MasterView, a virtual reality system that shows the expert's moves in first-person perspective so the user can imitate and practice.","tags":["hackathon","virtual-reality"],"title":"MasterView (VR System)","type":"project"},{"authors":null,"categories":null,"content":"Using common and well-known development tools, we transform slither.io, a game based on \u0026ldquo;Snake\u0026rdquo;, into an interactive augmented-reality game.\nThe details about this project can be found in our project report.\n","date":1466481600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1466481600,"objectID":"7e809bb8e24ae89c69857eefd8ae73f7","permalink":"https://people.csail.mit.edu/weifang/project/cg16-slitherio/","publishdate":"2016-06-21T00:00:00-04:00","relpermalink":"/weifang/project/cg16-slitherio/","section":"project","summary":"Using common and well-known development tools, we transform slither.io, a game based on 'Snake', into an interactive augmented-reality game.","tags":["augmented-reality","game","unity-3d"],"title":"Slither.AR (AR Game)","type":"project"},{"authors":null,"categories":null,"content":"We participated in the 2015 CAD Contest hosted by IEEE/ACM International Conference on Computer Aided Design (ICCAD 2015). In Problem B, we developed a system to identify equivalent cuts in both equivalent and nonequivalent circuits for design partitioning.\n","date":1442635200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1442635200,"objectID":"d5eda6b205971a1a39ae35b1932af6f5","permalink":"https://people.csail.mit.edu/weifang/project/cad15-eqcheck/","publishdate":"2015-09-19T00:00:00-04:00","relpermalink":"/weifang/project/cad15-eqcheck/","section":"project","summary":"In the 2015 CAD Contest, we developed a system to identify equivalent cuts in both equivalent and nonequivalent circuits for design partitioning.","tags":["contest","computer-aided-design","electronic-design-automation"],"title":"Large Scale Equivalence Checking and Functional Correction","type":"project"}]