[{"authors":["Chung-Wei Lee","Wei Fang","Chih-Kuan Yeh","Yu-Chiang Frank Wang"],"categories":null,"content":"","date":1529294400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529294400,"objectID":"7cb725c1a496898e77f21bbca64e32d1","permalink":"https://people.csail.mit.edu/weifang/publication/cvpr18-mlzsl/","publishdate":"2018-06-18T00:00:00-04:00","relpermalink":"/weifang/publication/cvpr18-mlzsl/","section":"publication","summary":"In this paper, we propose a novel deep learning architecture for multi-label zero-shot learning (ML-ZSL), which is able to predict multiple unseen class labels for each input instance. Inspired by the way humans utilize semantic knowledge between objects of interests, we propose a framework that incorporates knowledge graphs for describing the relationships between multiple labels. Our model learns an information propagation mechanism from the semantic label space, which can be applied to model the interdependencies between seen and unseen class labels. With such investigation of structured knowledge graphs for visual reasoning, we show that our model can be applied for solving multi-label classification and ML-ZSL tasks. Compared to state-of-the-art approaches, comparable or improved performances can be achieved by our method.","tags":[],"title":"Multi-Label Zero-Shot Learning with Structured Knowledge Graphs","type":"publication"},{"authors":null,"categories":null,"content":"Inspired by the way humans utilize semantic knowledge between objects of interests, we propose a novel deep learning framework that incorporates knowledge graphs for describing the relationships between multiple labels to achieve multi-label zero-shot learning (ML-ZSL).\n","date":1525147200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525147200,"objectID":"c287156946b1ea153bd66c38d3959521","permalink":"https://people.csail.mit.edu/weifang/project/vll18-mlzsl/","publishdate":"2018-05-01T00:00:00-04:00","relpermalink":"/weifang/project/vll18-mlzsl/","section":"project","summary":"Inspired by the way humans utilize semantic knowledge between objects of interests, we propose a novel deep learning framework that incorporates knowledge graphs for describing the relationships between multiple labels to achieve multi-label zero-shot learning (ML-ZSL). ","tags":["computer-vision","deep-learning"],"title":"Multi-Label Zero-Shot Recognition with Knowledge Graphs","type":"project"},{"authors":null,"categories":null,"content":" In this project, we try to perform cross-domain image retrieval across different art styles using sketches as queries. Given a sketch image and a target art domain, we aim to retrieve images that are semantically similar in that particular art domain.\nWe surveyed a few papers and a dataset by Adobe and Cornell Tech in the proceedings of this yearâ€™s ICCV conference (ICCV 2017). The Behance Artistic Media (BAM) dataset consists of images of 9 kinds of objects for 7 different art styles such as oil paint or vector art. We select a subset containing 5 content classes: bicycle, bird, cars, cat, and dog, as our retrieval database. During training, we utilized sketches from the Quick, Draw! dataset as queries, and we developed a demo system to test retrieval results for hand-drawn sketches. We approached this problem by utilizing triplet convolutional neural networks, mainly based on this paper.\nHere are our presentation slides.\nReference  BAM! The Behance Artistic Media Dataset for Recognition Beyond Photography. ICCV 2017. Sketching with Style: Visual Search with Sketches and Aesthetic Context. ICCV 2017.  ","date":1514782800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514782800,"objectID":"0f7789f3f381c10c5c435a6a40973b25","permalink":"https://people.csail.mit.edu/weifang/project/mmai17-retrieval/","publishdate":"2018-01-01T00:00:00-05:00","relpermalink":"/weifang/project/mmai17-retrieval/","section":"project","summary":"In this project, we try to perform cross-domain image retrieval across different art styles using sketches as queries. Given a sketch image and a target art domain, we aim to retrieve images that are semantically similar in that particular art domain.","tags":["computer-vision","deep-learning"],"title":"Sketch-based Image Retrieval across Art Styles","type":"project"},{"authors":null,"categories":null,"content":"","date":1512547267,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512547267,"objectID":"3b9aab79ece00dd76e6f31c7869bd79e","permalink":"https://people.csail.mit.edu/weifang/activities/ntueesa/","publishdate":"2017-12-06T16:01:07+08:00","relpermalink":"/weifang/activities/ntueesa/","section":"activities","summary":"","tags":[],"title":"NTUEE Student Association","type":"activities"},{"authors":null,"categories":null,"content":"","date":1506744000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506744000,"objectID":"60270818a58deed4f1d180afc91defa4","permalink":"https://people.csail.mit.edu/weifang/project/spml17-audio2vec/","publishdate":"2017-09-30T00:00:00-04:00","relpermalink":"/weifang/project/spml17-audio2vec/","section":"project","summary":"","tags":["speech-processing","deep-learning"],"title":"Audio Word Embeddings","type":"project"},{"authors":null,"categories":null,"content":"In this project, we built a modular dialogue system with deep learning techniques for the task of assisting people in department stores.\nHere is our poster.\n","date":1498017600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498017600,"objectID":"d5aebb69f8657b9f620f5e4d058502b2","permalink":"https://people.csail.mit.edu/weifang/project/icb17-chatbot/","publishdate":"2017-06-21T00:00:00-04:00","relpermalink":"/weifang/project/icb17-chatbot/","section":"project","summary":"We built a modular dialogue system with deep learning techniques for the task of assisting people in department stores.","tags":["natural-language-processing","deep-learning"],"title":"Modular Chatbot","type":"project"},{"authors":["Wei Fang","Jui-Yang Hsu","Hung-Yi Lee","Lin-Shan Lee"],"categories":null,"content":"","date":1481605200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1481605200,"objectID":"e1d9d9183569299e647714b01168d503","permalink":"https://people.csail.mit.edu/weifang/publication/slt16-toeflqa/","publishdate":"2016-12-13T00:00:00-05:00","relpermalink":"/weifang/publication/slt16-toeflqa/","section":"publication","summary":"Multimedia or spoken content presents more attractive information than plain text content, but the former is more difficult to display on a screen and be selected by a user. As a result, accessing large collections of the former is much more difficult and time-consuming than the latter for humans. It's therefore highly attractive to develop machines which can automatically understand spoken content and summarize the key information for humans to browse over. In this endeavor, a new task of machine comprehension of spoken content was proposed recently. The initial goal was defined as the listening comprehension test of TOEFL, a challenging academic English examination for English learners whose native languages are not English. An Attention-based Multi-hop Recurrent Neural Network (AMRNN) architecture was also proposed for this task, which considered only the sequential relationship within the speech utterances. In this paper, we propose a new Hierarchical Attention Model (HAM), which constructs multi-hopped attention mechanism over tree-structured rather than sequential representations for the utterances. Improved comprehension performance robust with respect to ASR errors were obtained.","tags":[],"title":"Hierarchical Attention Model for Improved Machine Comprehension of Spoken Content","type":"publication"},{"authors":null,"categories":null,"content":"Here is a short talk I gave on our group\u0026rsquo;s recent work on speech question answering.\n","date":1481605200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1481605200,"objectID":"b25204c6aee5255124eaf25f1fda6a2a","permalink":"https://people.csail.mit.edu/weifang/project/spml16-toeflqa/","publishdate":"2016-12-13T00:00:00-05:00","relpermalink":"/weifang/project/spml16-toeflqa/","section":"project","summary":"Here is a short talk I gave on our group\u0026rsquo;s recent work on speech question answering.","tags":["natural-language-processing","speech-processing","deep-learning"],"title":"Question Answering for Listening Comprehension","type":"project"},{"authors":null,"categories":null,"content":"In the 2016 HackNTU Hackathon, our team developed MasterView, a virtual reality system that shows the expert\u0026rsquo;s moves in first-person perspective so the user can imitate and practice.\nHere\u0026rsquo;s a demo video of our system, and here\u0026rsquo;s our presentation slides in Mandarin Chinese.\n","date":1471752000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471752000,"objectID":"d8e0b09f4ee3dde59068c7d5a000a01b","permalink":"https://people.csail.mit.edu/weifang/project/hackntu16-masterview/","publishdate":"2016-08-21T00:00:00-04:00","relpermalink":"/weifang/project/hackntu16-masterview/","section":"project","summary":"At the 2016 HackNTU Hackathon, our team developed MasterView, a virtual reality system that shows the expert's moves in first-person perspective so the user can imitate and practice.","tags":["hackathon","virtual-reality"],"title":"MasterView (VR System)","type":"project"},{"authors":null,"categories":null,"content":"Using common and well-known development tools, we transform slither.io, a game based on \u0026ldquo;Snake\u0026rdquo;, into an interactive augmented-reality game.\nThe details about this project can be found in our project report.\n","date":1466481600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1466481600,"objectID":"3838447251089f4aef5c946891476dfb","permalink":"https://people.csail.mit.edu/weifang/project/cg16-slither/","publishdate":"2016-06-21T00:00:00-04:00","relpermalink":"/weifang/project/cg16-slither/","section":"project","summary":"Using common and well-known development tools, we transform slither.io, a game based on 'Snake', into an interactive augmented-reality game.","tags":["augmented-reality","game","unity-3d"],"title":"Slither.AR (AR Game)","type":"project"},{"authors":null,"categories":null,"content":"Here is our report and here are our slides.\n","date":1462852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1462852800,"objectID":"28eb96160accaf3753ee3004571d99c6","permalink":"https://people.csail.mit.edu/weifang/project/uia16-vqa/","publishdate":"2016-05-10T00:00:00-04:00","relpermalink":"/weifang/project/uia16-vqa/","section":"project","summary":"Here is our report and here are our slides.","tags":["natural-language-processing","computer-vision","deep-learning"],"title":"Visual Question Answering","type":"project"},{"authors":null,"categories":null,"content":"Here is a report on our results for the aspect-based sentiment analysis task in SemEval 2016.\n","date":1454043600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1454043600,"objectID":"9f4a9070f4d81e6010ca11cd8c7bf7e1","permalink":"https://people.csail.mit.edu/weifang/project/spml15-absa/","publishdate":"2016-01-29T00:00:00-05:00","relpermalink":"/weifang/project/spml15-absa/","section":"project","summary":"Here is a report on our results for the aspect-based sentiment analysis task in SemEval 2016.","tags":["natural-language-processing","deep-learning"],"title":"Aspect-Based Sentiment Analysis","type":"project"},{"authors":null,"categories":null,"content":"We participated in the 2015 CAD Contest hosted by IEEE/ACM International Conference on Computer Aided Design (ICCAD 2015). In Problem B, we developed a system to identify equivalent cuts in both equivalent and nonequivalent circuits for design partitioning.\n","date":1442635200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1442635200,"objectID":"65885c3b974ce8ea4bc4c9c1daf397d5","permalink":"https://people.csail.mit.edu/weifang/project/cad15-eqcheck/","publishdate":"2015-09-19T00:00:00-04:00","relpermalink":"/weifang/project/cad15-eqcheck/","section":"project","summary":"In the 2015 CAD Contest, we developed a system to identify equivalent cuts in both equivalent and nonequivalent circuits for design partitioning.","tags":["contest","computer-aided-design","electronic-design-automation"],"title":"Large Scale Equivalence Checking and Functional Correction","type":"project"},{"authors":null,"categories":null,"content":"At the 2016 HackNTU Hackathon, our team built a second-hand trading platform, uhu, which provided services for booking, notifications, and filtering functions based on Facebook trading groups, in under 42 hours. Our presentation slides (in Mandarin Chinese) can be found here.\n","date":1440129600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1440129600,"objectID":"8f70a230e5b3fbd9d2f6529cac7b517d","permalink":"https://people.csail.mit.edu/weifang/project/hackntu15-uhu/","publishdate":"2015-08-21T00:00:00-04:00","relpermalink":"/weifang/project/hackntu15-uhu/","section":"project","summary":"At the 2016 HackNTU Hackathon, our team built a second-hand trading platform, uhu, which provided services for booking, notifications, and filtering functions based on Facebook trading groups, in under 42 hours.","tags":["hackathon","web"],"title":"uHu - a Resale Service","type":"project"}]